{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue2 as prologue\n",
    "\n",
    "print('libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data for the first project, we are using one of the functions of *dlc_practical_prologe.py* that randomly generates one for us given a size parameter. It returns a tuple containing the: *training set, targets, classes* and *testing set, targets, classes*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sets = prologue.generate_pair_sets(sample_size)\n",
    "\n",
    "train_set = sets[0]\n",
    "train_target = sets[1]\n",
    "train_classes = sets[2]\n",
    "\n",
    "test_set = sets[3]\n",
    "test_target = sets[4]\n",
    "test_classes = sets[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs are grayscale MNIST images consisting of two channels ($2 \\times 14 \\times 14$) representing two different digits. As visualized below, target vector contains the index of the channels which have the highest digit between the two (channel $0$ or $1$). \n",
    "\n",
    "Therefore, our task is to maximize the prediction of this boolean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first training data point with two channels, target is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('For the first training data point with two channels, target is {}'.format(train_target[0]))\n",
    "fig1, axes = plt.subplots(1, 2, figsize = (10, 7))\n",
    "ax = axes.ravel()\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].set_title('Channel #{} - Class: {}'.format(i, train_classes[0][i]))\n",
    "    ax[i].imshow(train_set[0][i], cmap='copper')\n",
    "    ax[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train the model by moving it through the given mini batch size and using Adam as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_epochs, eta, loss_criterion, model, train_input, train_target, mini_batch_size):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    for e in range(n_epochs):\n",
    "        acc_loss = 0 ## set error as 0 each iteration\n",
    "        ## Using mini-batches\n",
    "        optimizer.zero_grad()\n",
    "        for b in range(0, train_input.size(0), mini_batch_size): \n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            # print('Loss Shapes: Output: {}, Target: {}'.format(output.shape, train_target.narrow(0, b, mini_batch_size).shape))\n",
    "            loss = loss_criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            acc_loss = acc_loss + loss.item()\n",
    "\n",
    "            model.zero_grad() ## setting the gradients to zero before the loss calculation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= eta * p.grad\n",
    "                    \n",
    "    # print('Final Output: ', output, output.shape)\n",
    "    # print(torch.argmax(output, dim=1))\n",
    "    print('Model Training Finished - Final loss after {} epochs: {}'.format(n_epochs, acc_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Round the final values outputted from the network into binary values and compare them with the target binary matrix in order to get the number of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, input, target):\n",
    "    with torch.no_grad():\n",
    "        rounded_to_binary = torch.round(input)\n",
    "        errors = torch.where(rounded_to_binary != train_target)\n",
    "    return len(errors[0]) / target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt #1 - Binary Convolutional Network Classifier that takes the number of the hidden layers of the final fully connected layer as a parameter. \n",
    "\n",
    "As seen from the results below, it suffers from overfitting at the moment therefore it should be modified (dropout to be added next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCNN(nn.Module):\n",
    "    def __init__(self, hidden_layer_n): ## defining the layers\n",
    "        super().__init__()\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        self.flatten0 = nn.Flatten(0)\n",
    "        self.flatten1 = nn.Flatten(1)\n",
    "        \n",
    "        # Feature Extractors\n",
    "        self.conv1 = nn.Conv2d(2, 64, kernel_size=3, stride=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        # self.conv3 = nn.Conv2d(128, 128, kernel_size=1, stride=1)\n",
    "        \n",
    "        # Classifiers\n",
    "        self.fc1 = nn.Linear(512, hidden_layer_n)\n",
    "        self.fc2 = nn.Linear(hidden_layer_n, 1) ## output layers\n",
    "        \n",
    "    ## Generally, strides for convolution layers are 1 and for maxpools are 2\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), kernel_size = 2, stride = 2)\n",
    "        # print('First Conv Layer Shape', x.shape)\n",
    "        # x = self.dropout1(x)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), kernel_size = 2, stride = 2)\n",
    "        # print('Second Conv Layer Shape', x.shape)\n",
    "        # x = self.dropout1(x)\n",
    "        # x = F.max_pool2d(F.relu(self.conv3(x)), kernel_size = 2, stride = 2)\n",
    "        x = self.flatten1(x)\n",
    "        # print('After Flattening', x.shape)\n",
    "        x = self.fc1(x)\n",
    "        # print('First Connected Layer', x.shape)\n",
    "        # x = self.dropout1(x)\n",
    "\n",
    "        # x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.flatten0(x)\n",
    "        # print('Final Output Shape {} \\n'.format(x.shape))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarking with different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Finished - Final loss after 25 epochs: 0.03755403819377534\n",
      "Classification Error on the training set with 10 hidden layers: 0.0%\n",
      "Classification Error on the testing set with 10 hidden layers: 48.3%\n",
      "\n",
      "Model Training Finished - Final loss after 25 epochs: 0.02045655023539439\n",
      "Classification Error on the training set with 50 hidden layers: 0.0%\n",
      "Classification Error on the testing set with 50 hidden layers: 50.7%\n",
      "\n",
      "Model Training Finished - Final loss after 25 epochs: 5.405695426044986\n",
      "Classification Error on the training set with 200 hidden layers: 3.3000000000000003%\n",
      "Classification Error on the testing set with 200 hidden layers: 49.6%\n",
      "\n",
      "Model Training Finished - Final loss after 25 epochs: 2.987766152888071\n",
      "Classification Error on the training set with 500 hidden layers: 2.1999999999999997%\n",
      "Classification Error on the testing set with 500 hidden layers: 48.9%\n",
      "\n",
      "Model Training Finished - Final loss after 25 epochs: 11.493990674614906\n",
      "Classification Error on the training set with 1000 hidden layers: 9.4%\n",
      "Classification Error on the testing set with 1000 hidden layers: 49.6%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = [10, 50, 200, 500, 1000]\n",
    "model = BinaryCNN(hidden_layer_n=256)\n",
    "binary_criterion = nn.BCEWithLogitsLoss()\n",
    "eta = 1e-5\n",
    "mini_batch_size = 20\n",
    "nb_epochs = 15\n",
    "\n",
    "\n",
    "for layer_n in hidden_layers:   \n",
    "    model = BinaryCNN(hidden_layer_n = layer_n)\n",
    "    train_model(25, eta, binary_criterion, model, train_set, train_target.to(torch.float32), mini_batch_size)\n",
    "    \n",
    "    train_output = torch.sigmoid(model(train_set))\n",
    "    test_output = torch.sigmoid(model(test_set))\n",
    "    \n",
    "    error_train = compute_nb_errors(model, train_output, train_target)\n",
    "    error_test = compute_nb_errors(model, test_output, test_target)\n",
    "    \n",
    "    print('Classification Error on the training set with {} hidden layers: {}%'.format(layer_n, error_train * 100))\n",
    "    print('Classification Error on the testing set with {} hidden layers: {}%'.format(layer_n, error_test * 100))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6290ab70aa2c9e6859d722745d4fdeafb895ca1190e93c7ac9c8d926153eb965"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
